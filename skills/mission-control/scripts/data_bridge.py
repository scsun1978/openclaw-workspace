#!/usr/bin/env python3
"""
Mission Control æ•°æ®æ¡¥æ¥å™¨
ä» OpenClaw å¯¼å‡ºçš„çŠ¶æ€æ–‡ä»¶ä¸­è¯»å–çœŸå®æ•°æ®
"""

import json
import os
import re
import subprocess
import glob
from datetime import datetime
from pathlib import Path

# é…ç½®
WORKSPACE = Path("/Users/shengchun.sun/.openclaw/workspace")
VAULT_PATH = Path("/Users/shengchun.sun/Library/Mobile Documents/iCloud~md~obsidian/Documents/ctovault")
MISSION_CONTROL = VAULT_PATH / "Mission Control"

# Agent å®šä¹‰
AGENTS = [
    {"id": "scsun-monitor-agent", "name": "Monitor", "emoji": "ğŸ”", "role": "ç›‘æ§ä¸åè°ƒ"},
    {"id": "scsun-code-agent", "name": "Code", "emoji": "ğŸ’»", "role": "ä»£ç å®ç°"},
    {"id": "scsun-docs-agent", "name": "Docs", "emoji": "ğŸ“", "role": "æ–‡æ¡£ç¼–å†™"},
    {"id": "scsun-qa-agent", "name": "QA", "emoji": "ğŸ§ª", "role": "è´¨é‡æµ‹è¯•"},
]

# çŠ¶æ€å¯¼å‡ºæ–‡ä»¶
EXPORT_DIR = WORKSPACE / "mission-control-export"
CRON_EXPORT = EXPORT_DIR / "cron-status.json"
SESSIONS_EXPORT = EXPORT_DIR / "sessions-status.json"
SUBAGENTS_EXPORT = EXPORT_DIR / "subagents-status.json"
MEMORY_INDEX = EXPORT_DIR / "memory-index.json"
AGENT_MEMORY_EXPORT = EXPORT_DIR / "agent-memory-status.json"

def ensure_export_dir():
    """ç¡®ä¿å¯¼å‡ºç›®å½•å­˜åœ¨"""
    EXPORT_DIR.mkdir(parents=True, exist_ok=True)
    return EXPORT_DIR

def read_json(path, default=None):
    """å®‰å…¨è¯»å– JSON æ–‡ä»¶"""
    if path.exists():
        try:
            with open(path) as f:
                return json.load(f)
        except:
            pass
    return default or {}

def write_json(path, data):
    """å†™å…¥ JSON æ–‡ä»¶"""
    ensure_export_dir()
    with open(path, "w") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

def index_memory_files():
    """ç´¢å¼•æ‰€æœ‰ memory æ–‡ä»¶ï¼ˆé€’å½’æ‰«æå­ç›®å½•ï¼‰"""
    memory_dir = WORKSPACE / "memory"
    index = {
        "files": [],
        "last_update": datetime.now().isoformat(),
        "total_files": 0,
        "categories": {
            "daily": [],
            "stats": [],
            "index": []
        }
    }
    
    if memory_dir.exists():
        # æ‰«ææ ¹ç›®å½•
        for md_file in sorted(memory_dir.glob("*.md"), reverse=True):
            stat = md_file.stat()
            file_info = {
                "name": md_file.name,
                "path": str(md_file.relative_to(WORKSPACE)),
                "size": stat.st_size,
                "modified": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                "category": "index"
            }
            index["files"].append(file_info)
            index["categories"]["index"].append(file_info)
        
        # é€’å½’æ‰«æå­ç›®å½•
        for md_file in sorted(memory_dir.rglob("*.md"), reverse=True):
            if md_file.parent == memory_dir:
                continue  # è·³è¿‡æ ¹ç›®å½•ï¼ˆå·²å¤„ç†ï¼‰
            
            stat = md_file.stat()
            rel_path = str(md_file.relative_to(WORKSPACE))
            
            # æ ¹æ®è·¯å¾„ç¡®å®šåˆ†ç±»
            if "archive/daily" in rel_path:
                category = "daily"
            elif "archive/stats" in rel_path:
                category = "stats"
            else:
                category = "other"
            
            file_info = {
                "name": md_file.name,
                "path": rel_path,
                "size": stat.st_size,
                "modified": datetime.fromtimestamp(stat.st_mtime).isoformat(),
                "category": category
            }
            index["files"].append(file_info)
            if category in index["categories"]:
                index["categories"][category].append(file_info)
        
        index["total_files"] = len(index["files"])
    
    write_json(MEMORY_INDEX, index)
    return index

def get_agent_memory_status():
    """è·å–æ‰€æœ‰ Agent çš„ Memory çŠ¶æ€"""
    agent_status = []
    
    try:
        result = subprocess.run(
            ["openclaw", "memory", "status"],
            capture_output=True,
            text=True,
            timeout=30
        )
        output = result.stdout
        
        # è§£ææ¯ä¸ª agent çš„çŠ¶æ€
        current_agent = None
        agent_data = {}
        
        for line in output.split('\n'):
            line = line.strip()
            
            # æ£€æµ‹ agent åç§°
            if line.startswith('Memory Search ('):
                if current_agent and agent_data:
                    agent_status.append(agent_data)
                agent_name = re.search(r'Memory Search \(([^)]+)\)', line)
                current_agent = agent_name.group(1) if agent_name else None
                agent_data = {
                    "agent_id": current_agent,
                    "name": current_agent.replace("scsun-", "").replace("-agent", "").title(),
                    "indexed_files": 0,
                    "total_files": 0,
                    "chunks": 0,
                    "memory_files": 0,
                    "session_files": 0,
                    "embedding_model": "",
                    "status": "unknown"
                }
            
            elif current_agent:
                # è§£æç´¢å¼•ä¿¡æ¯: "Indexed: 528/1945 files Â· 2790 chunks"
                if line.startswith('Indexed:'):
                    match = re.search(r'Indexed: (\d+)/(\d+) files Â· (\d+) chunks', line)
                    if match:
                        agent_data["indexed_files"] = int(match.group(1))
                        agent_data["total_files"] = int(match.group(2))
                        agent_data["chunks"] = int(match.group(3))
                
                # è§£æ memory æ¥æº
                elif 'memory Â·' in line:
                    match = re.search(r'memory Â· (\d+)/(\d+) files', line)
                    if match:
                        agent_data["memory_files"] = int(match.group(1))
                
                # è§£æ sessions æ¥æº
                elif 'sessions Â·' in line:
                    match = re.search(r'sessions Â· (\d+)/(\d+) files', line)
                    if match:
                        agent_data["session_files"] = int(match.group(1))
                
                # è§£æ embedding model
                elif line.startswith('Model:'):
                    agent_data["embedding_model"] = line.replace('Model:', '').strip()
                
                # æ£€æµ‹å‘é‡çŠ¶æ€
                elif line.startswith('Vector:'):
                    agent_data["status"] = "ready" if "ready" in line else "error"
        
        # æ·»åŠ æœ€åä¸€ä¸ª agent
        if current_agent and agent_data:
            agent_status.append(agent_data)
    
    except Exception as e:
        print(f"âš ï¸ Failed to get agent memory status: {e}")
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    write_json(AGENT_MEMORY_EXPORT, {
        "agents": agent_status,
        "last_update": datetime.now().isoformat()
    })
    
    return agent_status

def generate_memory_canvas(agent_status=None):
    """ç”Ÿæˆ Memory Canvasï¼ˆæ”¯æŒåˆ†ç±»æ˜¾ç¤º + Agent è®°å¿†åˆ†æï¼‰"""
    index = read_json(MEMORY_INDEX, {"files": [], "categories": {}})
    
    nodes = [
        {
            "id": "title",
            "type": "text",
            "text": "# ğŸ§  Memory\n\nå¯æœç´¢çš„è®°å¿†åº“",
            "x": 0,
            "y": -600,
            "width": 400,
            "height": 100
        },
        {
            "id": "long-term",
            "type": "text",
            "text": """## ğŸ“š é•¿æœŸè®°å¿†

**æ–‡ä»¶**: `MEMORY.md`

å­˜å‚¨å†…å®¹:
- é‡è¦å†³ç­–
- é¡¹ç›®é‡Œç¨‹ç¢‘
- ç»éªŒæ•™è®­
- åå¥½è®¾ç½®

---
æœç´¢: `memory_search "å…³é”®è¯"`""",
            "x": -600,
            "y": -400,
            "width": 350,
            "height": 280,
            "color": "6"
        }
    ]
    
    # ç´¢å¼•æ–‡ä»¶ï¼ˆMEMORY-INDEX.mdï¼‰
    index_files = index.get("categories", {}).get("index", [])
    if index_files:
        for i, f in enumerate(index_files[:2]):
            nodes.append({
                "id": f"idx-{i}",
                "type": "text",
                "text": f"""### ğŸ“‹ {f['name']}

å¤§å°: {f['size']} bytes
ä¿®æ”¹: {f['modified'][:10]}""",
                "x": -200,
                "y": -400 + i * 120,
                "width": 300,
                "height": 100,
                "color": "4"
            })
    
    # æ¯æ—¥æ—¥å¿—
    daily_files = index.get("categories", {}).get("daily", [])
    if daily_files:
        daily_node = {
            "id": "daily-title",
            "type": "text",
            "text": f"## ğŸ“… æ¯æ—¥æ—¥å¿—\n\nå…± {len(daily_files)} ä¸ªæ–‡ä»¶",
            "x": 150,
            "y": -400,
            "width": 200,
            "height": 80,
            "color": "3"
        }
        nodes.append(daily_node)
        
        y_pos = -280
        for i, f in enumerate(daily_files[:4]):
            nodes.append({
                "id": f"daily-{i}",
                "type": "text",
                "text": f"ğŸ“„ {f['name'][:16]}\n{f['size']} bytes",
                "x": 150,
                "y": y_pos,
                "width": 180,
                "height": 60,
                "color": "0"
            })
            y_pos += 70
    
    # Agent è®°å¿†åˆ†æ
    if agent_status:
        # Agent åŒºåŸŸæ ‡é¢˜
        nodes.append({
            "id": "agents-title",
            "type": "text",
            "text": "## ğŸ¤– Agent è®°å¿†åˆ†æ\n\nå„ Agent çš„è®°å¿†å­˜å‚¨çŠ¶æ€",
            "x": -600,
            "y": -50,
            "width": 400,
            "height": 100,
            "color": "5"
        })
        
        # å„ Agent èŠ‚ç‚¹
        agent_colors = {"Monitor": "4", "Code": "3", "Docs": "2", "Qa": "1"}
        x_positions = [-600, -200, 200, 600]
        
        for i, agent in enumerate(agent_status[:4]):
            name = agent.get("name", "Unknown")
            chunks = agent.get("chunks", 0)
            indexed = agent.get("indexed_files", 0)
            total = agent.get("total_files", 0)
            mem_files = agent.get("memory_files", 0)
            sess_files = agent.get("session_files", 0)
            status = agent.get("status", "unknown")
            
            # æ ¹æ® chunks æ•°é‡å†³å®šçŠ¶æ€é¢œè‰²
            if chunks > 1000:
                status_emoji = "ğŸŸ¢"
                color = "4"
            elif chunks > 100:
                status_emoji = "ğŸŸ¡"
                color = "3"
            elif chunks > 0:
                status_emoji = "ğŸŸ "
                color = "1"
            else:
                status_emoji = "âšª"
                color = "0"
            
            # Agent emoji
            agent_emoji = {"Monitor": "ğŸ”", "Code": "ğŸ’»", "Docs": "ğŸ“", "Qa": "ğŸ§ª"}.get(name, "ğŸ¤–")
            role = {"Monitor": "ç›‘æ§", "Code": "ä»£ç ", "Docs": "æ–‡æ¡£", "Qa": "æµ‹è¯•"}.get(name, "")
            
            nodes.append({
                "id": f"agent-{i}",
                "type": "text",
                "text": f"""### {status_emoji} {agent_emoji} {name}

**è§’è‰²**: {role}
**Chunks**: {chunks:,}
**æ–‡ä»¶**: {indexed}/{total}
- Memory: {mem_files}
- Sessions: {sess_files}

**çŠ¶æ€**: {status}""",
                "x": x_positions[i] if i < len(x_positions) else -600 + i * 400,
                "y": 100,
                "width": 350,
                "height": 220,
                "color": color
            })
    
    # æ€»ç»Ÿè®¡
    total_chunks = sum(a.get("chunks", 0) for a in (agent_status or []))
    total_indexed = sum(a.get("indexed_files", 0) for a in (agent_status or []))
    
    nodes.append({
        "id": "stats",
        "type": "text",
        "text": f"""## ğŸ“Š æ€»ä½“ç»Ÿè®¡

**æ–‡ä»¶ç³»ç»Ÿ**
- **æ€»è®¡**: {index.get('total_files', 0)} ä¸ªæ–‡ä»¶
- **ç´¢å¼•**: {len(index_files)}
- **æ—¥å¿—**: {len(daily_files)}

**Agent è®°å¿†**
- **æ€» Chunks**: {total_chunks:,}
- **æ€»ç´¢å¼•æ–‡ä»¶**: {total_indexed}

---
æ›´æ–°: {datetime.now().strftime('%Y-%m-%d %H:%M')}""",
        "x": 400,
        "y": 100,
        "width": 350,
        "height": 280,
        "color": "5"
    })
    
    canvas = {"nodes": nodes, "edges": []}
    canvas_path = MISSION_CONTROL / "Memory.canvas"
    with open(canvas_path, "w") as f:
        json.dump(canvas, f, indent=2)
    print(f"âœ… Updated Memory.canvas ({len(nodes)} nodes)")

def format_schedule(job):
    """æ ¼å¼åŒ–è°ƒåº¦ä¿¡æ¯"""
    schedule = job.get("schedule", {})
    kind = schedule.get("kind", "unknown")
    
    if kind == "every":
        every_ms = schedule.get("everyMs", 0)
        if every_ms >= 3600000:
            return f"æ¯ {every_ms // 3600000} å°æ—¶"
        elif every_ms >= 60000:
            return f"æ¯ {every_ms // 60000} åˆ†é’Ÿ"
        else:
            return f"æ¯ {every_ms // 1000} ç§’"
    elif kind == "cron":
        return f"Cron: {schedule.get('expr', 'unknown')}"
    elif kind == "at":
        return "ä¸€æ¬¡æ€§ä»»åŠ¡"
    return "unknown"

def format_next_run(job):
    """æ ¼å¼åŒ–ä¸‹æ¬¡è¿è¡Œæ—¶é—´"""
    state = job.get("state", {})
    next_ms = state.get("nextRunAtMs")
    if next_ms:
        return datetime.fromtimestamp(next_ms / 1000).strftime('%Y-%m-%d %H:%M')
    return "N/A"

def generate_calendar_canvas(cron_data):
    """ç”Ÿæˆ Calendar Canvas"""
    nodes = [
        {
            "id": "title",
            "type": "text",
            "text": "# ğŸ“… Calendar\n\nCron Jobs & Scheduled Tasks",
            "x": 0,
            "y": -400,
            "width": 400,
            "height": 100
        }
    ]
    
    jobs = cron_data.get("jobs", [])
    
    # æ´»è·ƒä»»åŠ¡
    active_jobs = [j for j in jobs if j.get("enabled")]
    
    y_pos = -200
    for i, job in enumerate(active_jobs[:6]):
        name = job.get("name", "unknown")
        state = job.get("state", {})
        status = state.get("lastStatus", "unknown")
        schedule_str = format_schedule(job)
        next_run = format_next_run(job)
        
        status_emoji = "âœ…" if status == "ok" else "âŒ" if status == "error" else "â³"
        
        nodes.append({
            "id": f"job-{i}",
            "type": "text",
            "text": f"""## {status_emoji} {name}

**çŠ¶æ€**: {status}
**é¢‘ç‡**: {schedule_str}
**ä¸‹æ¬¡**: {next_run}""",
            "x": -300 if i % 2 == 0 else 100,
            "y": y_pos + (i // 2) * 200,
            "width": 380,
            "height": 160,
            "color": "4" if status == "ok" else "1" if status == "error" else "3"
        })
    
    # ç»Ÿè®¡
    ok_count = len([j for j in active_jobs if j.get("state", {}).get("lastStatus") == "ok"])
    error_count = len([j for j in active_jobs if j.get("state", {}).get("lastStatus") == "error"])
    
    nodes.append({
        "id": "stats",
        "type": "text",
        "text": f"""## ğŸ“Š ç»Ÿè®¡

- **æ€»ä»»åŠ¡**: {len(jobs)}
- **å·²å¯ç”¨**: {len(active_jobs)}
- **è¿è¡Œä¸­**: {ok_count}
- **é”™è¯¯**: {error_count}

---
åŒæ­¥: {datetime.now().strftime('%Y-%m-%d %H:%M')}""",
        "x": 0,
        "y": 400,
        "width": 400,
        "height": 200,
        "color": "5"
    })
    
    canvas = {"nodes": nodes, "edges": []}
    canvas_path = MISSION_CONTROL / "Calendar.canvas"
    with open(canvas_path, "w") as f:
        json.dump(canvas, f, indent=2)
    print(f"âœ… Updated Calendar.canvas ({len(nodes)} nodes)")

def main():
    print("ğŸŒ‰ Mission Control Data Bridge")
    print("=" * 50)
    
    # ç´¢å¼• memory æ–‡ä»¶
    mem_index = index_memory_files()
    print(f"ğŸ“š Indexed {mem_index['total_files']} memory files")
    
    # è·å– Agent Memory çŠ¶æ€
    agent_status = get_agent_memory_status()
    print(f"ğŸ¤– Analyzed {len(agent_status)} agents memory")
    for agent in agent_status:
        print(f"   - {agent['name']}: {agent['chunks']} chunks")
    
    # ç”Ÿæˆ Memory Canvas (åŒ…å« Agent åˆ†æ)
    generate_memory_canvas(agent_status)
    
    # è¯»å– cron æ•°æ®ï¼ˆéœ€è¦å…ˆå¯¼å‡ºï¼‰
    cron_data = read_json(CRON_EXPORT, {"jobs": []})
    if cron_data.get("jobs"):
        generate_calendar_canvas(cron_data)
        print(f"ğŸ“… Processed {len(cron_data['jobs'])} cron jobs")
    else:
        print("âš ï¸ No cron data found. Run export first.")
    
    print("=" * 50)
    print("âœ¨ Bridge complete")

if __name__ == "__main__":
    main()
